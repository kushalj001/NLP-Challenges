{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is spin as it relates to subatomic partic...</td>\n",
       "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is your simplest explanation of the strin...</td>\n",
       "      <td>&lt;p&gt;How would you explain string theory to non ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lie theory, Representations and particle physics</td>\n",
       "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Will Determinism be ever possible?</td>\n",
       "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Hamilton's Principle</td>\n",
       "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is spin as it relates to subatomic partic...   \n",
       "1   2  What is your simplest explanation of the strin...   \n",
       "2   3   Lie theory, Representations and particle physics   \n",
       "3   7                 Will Determinism be ever possible?   \n",
       "4   9                               Hamilton's Principle   \n",
       "\n",
       "                                             content  \n",
       "0  <p>I often hear about subatomic particles havi...  \n",
       "1  <p>How would you explain string theory to non ...  \n",
       "2  <p>This is a question that has been posted at ...  \n",
       "3  <p>What are the main problems that we need to ...  \n",
       "4  <p>Hamilton's principle states that a dynamic ...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('transfer-learning-on-stack-exchange-tags/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(html):\n",
    "    \n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "#print(stopwords)\n",
    "def remove_urls(text):\n",
    "    \n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \n",
    "    chars = [char for char in text if char not in string.punctuation]\n",
    "    text = ''.join([char for char in chars])\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \n",
    "    text_lower = [x.lower() for x in text]\n",
    "    text = ''.join([x for x in text_lower])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    processed_text = [word for word in tokens if word not in stopwords]\n",
    "    processed_text = ' '.join([word for word in processed_text])\n",
    "    return processed_text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    clean_text = ' '.join([word for word in lemmas])\n",
    "    return clean_text\n",
    "\n",
    "def remove_useless_words(text):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filter_tags = ['CD','FW','JJ','JJR','JJS','NN','NNP','NNPS','NNS','RB','RBR','RBS']\n",
    "    pos_tags = []\n",
    "    filtered_list = []\n",
    "    for token in tokens:\n",
    "        pos_tags.append(nltk.pos_tag(token))\n",
    "    \n",
    "    for (word,tag) in pos_tags:\n",
    "        if tag in filter_tags:\n",
    "            filtered_list.append(word)\n",
    "            \n",
    "    filtered_text = ' '.join([word for word in filtered_list])  \n",
    "    return filtered_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data['content'] = test_data['content'].apply(lambda x:remove_useless_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['content'] = test_data['content'].apply(lambda x:remove_html_tags(x))\n",
    "test_data['content'] = test_data['content'].apply(lambda x:remove_punctuation(x))\n",
    "test_data['content'] = test_data['content'].apply(lambda x:remove_stopwords(x))\n",
    "test_data['content'] = test_data['content'].apply(lambda x:lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['title'] = test_data['title'].apply(lambda x:remove_html_tags(x))\n",
    "test_data['title'] = test_data['title'].apply(lambda x:remove_punctuation(x))\n",
    "test_data['title'] = test_data['title'].apply(lambda x:remove_stopwords(x))\n",
    "test_data['title'] = test_data['title'].apply(lambda x:lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_data[:4000]\n",
    "test_data.to_pickle('processed_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_matrix = vectorizer.fit_transform(list(data['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# def get_freq(text):\n",
    "#     vector = vectorizer.transform([text])\n",
    "#     vector = vector[vector.nonzero()]\n",
    "#     return vector\n",
    "# data['vectors'] = data['content'].apply(lambda x:get_freq(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True,limit=600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "for word,freq in vectorizer.vocabulary_.items():\n",
    "    if len(word.split()) == 2:\n",
    "        word = '_'.join([x for x in word.split()])\n",
    "    keywords.append(word)\n",
    "    \n",
    "def get_tf_words(text):\n",
    "    keyword_from_content = []\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    for word in tokens:\n",
    "        if word in keywords:\n",
    "            keyword_from_content.append(word)\n",
    "    \n",
    "    return keyword_from_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['keywords'] = data['content'].apply(lambda x:get_tf_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(features.shape[0])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "for doc_index in range(4000):\n",
    "    sampled_words = []\n",
    "    feature_index = tfidf_matrix[doc_index,:].nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [tfidf_matrix[doc_index, x] for x in feature_index])\n",
    "    for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "        if s >= 0.1:\n",
    "            sampled_words.append(w)\n",
    "            #print(w, s)\n",
    "    data['keywords'][doc_index] = sampled_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_vector = embeddings['physics']\n",
    "def get_tags(keywords):\n",
    "    sims = []\n",
    "    for keyword in keywords:\n",
    "        if keyword in embeddings.wv.vocab:\n",
    "            keyword_vector = embeddings[keyword]\n",
    "            sim = np.dot(physics_vector,keyword_vector.T)\n",
    "            sims.append((sim,keyword))\n",
    "    sims = list(set(sims))        \n",
    "    sorted_sims = sorted(sims)\n",
    "    tags = sorted_sims[-3:]\n",
    "    tags = [tag[1] for tag in tags]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "c:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['tags'] = data['keywords'].apply(lambda x:get_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>spin relates subatomic particle</td>\n",
       "      <td>often hear subatomic particle property called ...</td>\n",
       "      <td>[often, hear, subatomic, particle, property, c...</td>\n",
       "      <td>[spin, particle, subatomic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>simplest explanation string theory</td>\n",
       "      <td>would explain string theory non physicist im s...</td>\n",
       "      <td>[would, explain, string, theory, non, physicis...</td>\n",
       "      <td>[plausible, theory, physicist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>lie theory representation particle physic</td>\n",
       "      <td>question posted many different forum thought m...</td>\n",
       "      <td>[question, posted, many, different, forum, tho...</td>\n",
       "      <td>[symmetry, invariant, physicist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>determinism ever possible</td>\n",
       "      <td>main problem need solve prove laplace determin...</td>\n",
       "      <td>[main, problem, need, solve, prove, laplace, d...</td>\n",
       "      <td>[principle, solve, determinism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>hamilton principle</td>\n",
       "      <td>hamilton principle state dynamic system always...</td>\n",
       "      <td>[hamilton, principle, state, dynamic, system, ...</td>\n",
       "      <td>[dynamic, stationary, principle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      title  \\\n",
       "0   1            spin relates subatomic particle   \n",
       "1   2         simplest explanation string theory   \n",
       "2   3  lie theory representation particle physic   \n",
       "3   7                  determinism ever possible   \n",
       "4   9                         hamilton principle   \n",
       "\n",
       "                                             content  \\\n",
       "0  often hear subatomic particle property called ...   \n",
       "1  would explain string theory non physicist im s...   \n",
       "2  question posted many different forum thought m...   \n",
       "3  main problem need solve prove laplace determin...   \n",
       "4  hamilton principle state dynamic system always...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [often, hear, subatomic, particle, property, c...   \n",
       "1  [would, explain, string, theory, non, physicis...   \n",
       "2  [question, posted, many, different, forum, tho...   \n",
       "3  [main, problem, need, solve, prove, laplace, d...   \n",
       "4  [hamilton, principle, state, dynamic, system, ...   \n",
       "\n",
       "                               tags  \n",
       "0       [spin, particle, subatomic]  \n",
       "1    [plausible, theory, physicist]  \n",
       "2  [symmetry, invariant, physicist]  \n",
       "3   [principle, solve, determinism]  \n",
       "4  [dynamic, stationary, principle]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
